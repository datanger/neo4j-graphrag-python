#!/usr/bin/env python3
#
#  Copyright (c) "Neo4j"
#  Neo4j Sweden AB [https://neo4j.com]
#  #
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#  #
#      https://www.apache.org/licenses/LICENSE-2.0
#  #
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

from __future__ import annotations

import os
import asyncio
import json
import logging
from typing import List, Dict, Any, Optional, Union, Tuple
from pathlib import Path
import json
import logging
from datetime import datetime
import numpy as np
from typing import List, Optional, Union
import sys

# Add comprehensive logging to see all steps
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stdout
)

import asyncio
import neo4j
from neo4j_graphrag.llm.base import LLMInterface
from neo4j_graphrag.experimental.components.code_extractor.matlab.matlab_extractor import (
    MatlabExtractor, MatlabExtractionResult, get_global_registry
)
from neo4j_graphrag.experimental.components.entity_relation_extractor import (
    LLMEntityRelationExtractor,
    OnError,
)
from neo4j_graphrag.experimental.components.kg_writer import Neo4jWriter
from neo4j_graphrag.experimental.components.types import LexicalGraphConfig
from neo4j_graphrag.experimental.components.schema import (
    GraphSchema,
    NodeType,
    PropertyType,
    RelationshipType,
)
from neo4j_graphrag.experimental.components.types import (
    Neo4jGraph,
    TextChunk,
    TextChunks,
    DocumentInfo,
    LexicalGraphConfig,
)
from neo4j_graphrag.experimental.pipeline import Pipeline
from neo4j_graphrag.experimental.pipeline.component import DataModel
from neo4j_graphrag.generation.prompts import PromptTemplate
from neo4j_graphrag.experimental.components.code_extractor.matlab.requirements import EXAMPLES, SCHEMA
from neo4j_graphrag.experimental.components.code_extractor.matlab.post_processor import MatlabPostProcessor


class Neo4jGraphResult(DataModel):
    graph: Neo4jGraph

class CodeExtractionTemplate(PromptTemplate):
    DEFAULT_TEMPLATE = """
You are a top-tier algorithm designed for extracting a labeled property graph schema in
structured formats.

Generate a generalized graph schema based on the input text. Identify key entity types,
their relationship types, and property types.

IMPORTANT RULES:
1. Return only abstract schema information, not concrete instances.
2. Use singular PascalCase labels for entity types (e.g., Person, Company, Product).
3. Use UPPER_SNAKE_CASE for relationship types (e.g., WORKS_FOR, MANAGES).
4. Include property definitions only when the type can be confidently inferred, otherwise omit them.
5. When defining potential_schema, ensure that every entity and relation mentioned exists in your entities and relations lists.
6. Do not create entity types that aren't clearly mentioned in the text.
7. Keep your schema minimal and focused on clearly identifiable patterns in the text.

Accepted property types are: BOOLEAN, DATE, DURATION, FLOAT, INTEGER, LIST,
LOCAL_DATETIME, LOCAL_TIME, POINT, STRING, ZONED_DATETIME, ZONED_TIME.

Return a valid JSON object that follows this precise structure:
{schema}

Examples:
{examples}

Please return a JSON object according to the above instructions based on the following file path and input text.

File path:
{file_path}

Input text:
```{code_type}
{text}
```
"""
    EXPECTED_INPUTS = ["text"]

    def format(
        self,
        text: str = "",
        schema: str = "",
        file_path: str = "",
        examples: str = "",
        code_type: str = "matlab",
    ) -> str:
        return super().format(text=text, schema=schema, file_path=file_path, examples=examples, code_type=code_type)

class MockLLM:
    """Mock LLM for demonstration purposes."""

    async def generate(self, prompt: str) -> str:
        """Return a mock description."""
        return "Mock description generated by LLM"

def convert_to_native(value):
    """Recursively convert value and all its contents to native Python types."""
    try:
        if value is None:
            return None

        # Handle numpy and other numeric types
        if hasattr(value, 'item') and hasattr(value, 'dtype'):
            value = value.item()  # Convert numpy scalar to Python native

        # Handle basic types
        if isinstance(value, bool):
            return value

        # Handle string type
        if isinstance(value, str):
            # Try to convert to number if it looks like a number
            try:
                if value.lower() in ('true', 'false'):
                    return value.lower() == 'true'
                if '.' in value or 'e' in value.lower():
                    fval = float(value)
                    return int(fval) if fval.is_integer() else fval
                return int(value)
            except (ValueError, TypeError):
                return value

        # Handle numeric types - ensure they're native Python types
        if isinstance(value, (int, float)):
            # Convert to int if it's a whole number, otherwise float
            if float(value).is_integer():
                return int(value)
            return float(value)

        # Handle numpy numeric types
        if 'numpy' in str(type(value)) and hasattr(value, 'item'):
            try:
                return convert_to_native(value.item())
            except:
                pass

        # Handle lists and tuples
        if isinstance(value, (list, tuple)):
            return [convert_to_native(x) for x in value]

        # Handle dictionaries
        if isinstance(value, dict):
            return {str(k): convert_to_native(v) for k, v in value.items()}

        # Handle datetime objects
        if hasattr(value, 'isoformat'):
            return value.isoformat()

        # Try to convert to a basic type
        try:
            # Try to get a primitive representation
            if hasattr(value, '__dict__'):
                return {str(k): convert_to_native(v) for k, v in value.__dict__.items()}

            # Try to convert to string as last resort
            str_val = str(value)
            if str_val != str(type(value)):  # Only return if it's a meaningful string representation
                return str_val

            # If we get here, the default string representation isn't helpful
            return None

        except Exception as e:
            print(f"Warning: Could not convert value {value} of type {type(value)}: {e}")
            return None

    except Exception as e:
        print(f"Error in convert_to_native for value {value} of type {type(value)}: {e}")
        return None

def convert_value(value):
    """Convert value to a Neo4j-compatible type with detailed logging."""
    try:
        original_type = type(value).__name__
        converted = convert_to_native(value)

        # Log conversion if the type changed
        if converted is not None and str(converted) != str(value):
            print(f"  Converted {original_type}: {value!r} -> {type(converted).__name__}: {converted!r}")

        return converted
    except Exception as e:
        print(f"Error converting value {value!r} of type {type(value)}: {e}")
        return None

def convert_item(item):
    """Convert a single item to a Neo4j-compatible type."""
    return convert_value(item)

def validate_properties(properties, context):
    """Validate and convert properties to Neo4j-compatible types."""
    if not properties:
        return {}

    valid_props = {}
    for key, value in properties.items():
        try:
            # Skip None values
            if value is None:
                continue

            # Convert the value
            converted = convert_value(value)

            # Check for problematic types
            if converted is not None:
                if isinstance(converted, (list, tuple, dict)):
                    # Check nested structures
                    def check_nested(v):
                        if isinstance(v, (list, tuple)):
                            return all(check_nested(x) for x in v)
                        if isinstance(v, dict):
                            return all(isinstance(k, str) and check_nested(x) for k, x in v.items())
                        return isinstance(v, (str, int, float, bool, type(None)))

                    if not check_nested(converted):
                        print(f"  WARNING: {context} has non-serializable nested type in property '{key}': {converted}")
                        converted = str(converted)

                valid_props[key] = converted

        except Exception as e:
            print(f"  ERROR: Failed to convert {context} property '{key}': {e}")
            try:
                valid_props[key] = str(value)
            except:
                print(f"  ERROR: Could not stringify property '{key}', skipping")

    return valid_props

def ensure_neo4j_compatible(value, path=''):
    """Ensure a value is Neo4j-compatible, converting if necessary."""
    if value is None:
        return None

    # Handle numpy and other numeric types
    if hasattr(value, 'item') and hasattr(value, 'dtype'):
        try:
            return ensure_neo4j_compatible(value.item(), path)
        except Exception:
            return str(value)

    # Handle standard Python types
    if isinstance(value, (bool, np.bool_)):
        return bool(value)
    elif isinstance(value, (int, np.integer)):
        return int(value)
    elif isinstance(value, (float, np.floating)):
        if float(value).is_integer():
            return int(value)
        return float(value)
    elif isinstance(value, str):
        return value
    elif isinstance(value, (list, tuple)):
        return [ensure_neo4j_compatible(x, f"{path}[{i}]") for i, x in enumerate(value)]
    elif isinstance(value, dict):
        return {str(k): ensure_neo4j_compatible(v, f"{path}.{k}" if path else k) for k, v in value.items()}
    else:
        print(f"Converting unsupported type {type(value).__name__} to string at {path}")
        return str(value)

async def process_matlab_files(directory: str, llm: LLMInterface, entry_script_path: str = None) -> 'MatlabExtractionResult':
    """Process MATLAB files in the given directory using the MatlabExtractor."""
    # Initialize the extractor with the LLM and entry script
    # extractor = LLMEntityRelationExtractor(llm=llm, prompt_template=CodeExtractionTemplate())
    extractor = MatlabExtractor(llm=llm, entry_script_path=entry_script_path)

    # Find all .m files in the directory
    matlab_files = list(Path(directory).rglob("*.m"))

    # Initialize result with empty graph
    result_graph = Neo4jGraph()

    # Process each file individually
    for file_path in matlab_files:
        # Read the file content
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Create a text chunk with required fields
        chunk = TextChunk(
            text=content,
            index=0,
            metadata={"file_path": str(file_path), "file_name": file_path.name, "code_type": "matlab"}
        )

        # Create document info with required path field for this file
        doc_info = DocumentInfo(
            path=str(file_path),
            metadata={"name": file_path.name}
        )

        # Process the current file, but disable post-processing inside the loop
        file_result = await extractor.run(
            chunks=TextChunks(chunks=[chunk]),
            schema=SCHEMA,
            document_info=doc_info,
            lexical_graph_config=LexicalGraphConfig(),
            examples=EXAMPLES,
            enable_post_processing=False,
        )

        # Merge the results
        if file_result and hasattr(file_result, 'graph') and file_result.graph:
            result_graph.nodes.extend(file_result.graph.nodes)
            result_graph.relationships.extend(file_result.graph.relationships)

    # After processing all files, run the post-processing step once on the aggregated graph
    print("Applying final cross-file relationship post-processing...")
    final_graph = MatlabPostProcessor().post_process_cross_file_relationships(result_graph)

    # Return the combined result graph
    result = type('Result', (), {'graph': final_graph})()

    # Process all nodes with detailed validation
    for i, node in enumerate(result.graph.nodes):
        if not hasattr(node, 'properties'):
            print(f"Node {i} has no properties")
            node.properties = {}
            continue

        node_id = getattr(node, 'id', f'node_{i}')
        node_label = getattr(node, 'label', 'UNKNOWN')
        print(f"\nValidating node {i} ({node_label}): {node_id}")

        # Convert line_range if it exists
        if 'line_range' in node.properties:
            try:
                line_ranges = node.properties['line_range']
                if isinstance(line_ranges, list) and line_ranges and isinstance(line_ranges[0], (list, tuple)) and len(line_ranges[0]) == 2:
                    # Convert list of tuples to a string representation
                    line_ranges_str = '; '.join(
                        f'"{str(code)}" at lines {str(line_range)}'
                        for code, line_range in line_ranges
                    )
                    node.properties['line_range'] = line_ranges_str
                elif line_ranges is not None:
                    print(f"  Warning: Unexpected line_range format: {type(line_ranges)}")
            except Exception as e:
                print(f"  Error processing line_range: {e}")

        # Validate and convert all properties
        node.properties = validate_properties(node.properties, f"node {node_id}")

    # Process all relationships with detailed validation
    for i, rel in enumerate(result.graph.relationships):
        if not hasattr(rel, 'properties'):
            print(f"Relationship {i} has no properties")
            rel.properties = {}
            continue

        rel_type = getattr(rel, 'type', 'UNKNOWN')
        rel_id = f"{getattr(rel, 'start_node_id', '?')} -[{rel_type}]-> {getattr(rel, 'end_node_id', '?')}"
        print(f"\nValidating relationship {i}: {rel_id}")

        # Validate and convert all properties
        rel.properties = validate_properties(rel.properties, f"relationship {i}")

    return result

async def process_matlab_files_post_processing_only(directory: str, llm: LLMInterface, entry_script_path: str = None) -> 'MatlabExtractionResult':
    """Process MATLAB files with post-processing only, using existing data.
    
    This function is used when we want to update only the post-processing
    without rebuilding all the data from scratch.
    
    Args:
        directory: Directory containing MATLAB files
        llm: Language model interface
        entry_script_path: Path to entry script for execution flow analysis
        
    Returns:
        MatlabExtractionResult: The result containing the extracted graph
    """
    # Initialize the extractor with the LLM and entry script
    extractor = MatlabExtractor(llm=llm, entry_script_path=entry_script_path)
    
    # Create a dummy chunk to trigger post-processing
    dummy_chunk = TextChunk(
        text="",
        index=0,
        metadata={"file_path": "dummy", "file_name": "dummy.m", "code_type": "matlab"}
    )
    
    # Create dummy document info
    doc_info = DocumentInfo(
        path="dummy",
        metadata={"name": "dummy"}
    )
    
    # Run with rebuild_data=False to use existing data
    result = await extractor.run(
        chunks=TextChunks(chunks=[dummy_chunk]),
        schema=SCHEMA,
        document_info=doc_info,
        lexical_graph_config=LexicalGraphConfig(),
        examples=EXAMPLES,
        enable_post_processing=True,
        rebuild_data=False,
    )
    
    return result

async def main():
    # 解析命令行参数
    import argparse
    
    parser = argparse.ArgumentParser(description='MATLAB Code Knowledge Graph Builder')
    parser.add_argument('--matlab_dir', type=str, default="tests/matlab_test/test_data",
                       help='Directory containing MATLAB files')
    parser.add_argument('--entry_script', type=str, default=None,
                       help='Path to the entry script for execution flow analysis')
    parser.add_argument('--rebuild_data', action='store_true',
                       help='Rebuild all data instead of using existing data')
    parser.add_argument('--neo4j_uri', type=str, default="bolt://localhost:7687",
                       help='Neo4j connection URI')
    parser.add_argument('--neo4j_user', type=str, default="neo4j",
                       help='Neo4j username')
    parser.add_argument('--neo4j_password', type=str, default="password",
                       help='Neo4j password')
    parser.add_argument('--neo4j_db', type=str, default="neo4j",
                       help='Neo4j database name')
    
    args = parser.parse_args()
    
    # Initialize LLM
    llm = MockLLM()

    # Directory containing MATLAB files
    matlab_dir = args.matlab_dir
    entry_script_path = args.entry_script

    # Neo4j connection settings
    NEO4J_URI = args.neo4j_uri
    NEO4J_USER = args.neo4j_user
    NEO4J_PASSWORD = args.neo4j_password
    NEO4J_DB = args.neo4j_db

    driver = None  # Initialize driver to None
    try:
        # Initialize Neo4j driver
        driver = neo4j.GraphDatabase.driver(
            NEO4J_URI,
            auth=(NEO4J_USER, NEO4J_PASSWORD)
        )

        # --- Clear the database before writing ---
        print("Connecting to Neo4j to clear the database...")
        with driver.session(database=NEO4J_DB) as session:
            session.run("MATCH (n) DETACH DELETE n")
        print("Database cleared successfully.")

        # 检查是否需要重新构建数据
        rebuild_data = args.rebuild_data
        
        # 检查是否存在已构建的数据
        existing_data = len(get_global_registry().all_nodes) > 0
        
        # Process MATLAB files and get the extraction result
        if not existing_data or rebuild_data:
            if not existing_data:
                print("No existing data found, building from scratch...")
            else:
                print("Rebuild flag set, rebuilding all data...")
                # 清除现有数据
                get_global_registry().reset_global_registry()
            
            # 处理MATLAB文件
            result = await process_matlab_files(matlab_dir, llm, entry_script_path)
        else:
            print("Using existing data, only updating post-processing...")
            # 只更新后处理
            result = await process_matlab_files_post_processing_only(matlab_dir, llm, entry_script_path)
            
        graph = result.graph  # Access the Neo4jGraph from the result
        print(f"Extracted graph with {len(graph.nodes)} nodes and {len(graph.relationships)} relationships")
        
        # Add debug information
        print(f"DEBUG: Original graph nodes: {len(graph.nodes)}")
        print(f"DEBUG: Original graph relationships: {len(graph.relationships)}")
        
        # Print first few nodes and relationships for debugging
        if graph.nodes:
            print(f"DEBUG: First node: {graph.nodes[0]}")
        if graph.relationships:
            print(f"DEBUG: First relationship: {graph.relationships[0]}")

        # Initialize Neo4j writer
        writer = Neo4jWriter(
            driver=driver,
            neo4j_database=NEO4J_DB
        )

        # Convert graph nodes and relationships to dictionaries
        nodes = []
        relationships = []

        # Process nodes with property validation
        print(f"DEBUG: Processing {len(graph.nodes)} nodes...")
        for node in graph.nodes:
            try:
                node_dict = dict(node)
                # Convert properties to native types
                properties = {}
                for k, v in node_dict.get('properties', {}).items():
                    try:
                        properties[k] = ensure_neo4j_compatible(v, f"node.{node_dict.get('id', '?')}.{k}")
                    except Exception as e:
                        print(f"Error processing node {node_dict.get('id', '?')} property '{k}': {e}")

                # Create a clean node dictionary
                clean_node = {
                    'id': str(node_dict.get('id', '')),
                    'label': str(node_dict.get('label', '')),
                    'properties': properties
                }
                nodes.append(clean_node)
            except Exception as e:
                print(f"Error processing node {getattr(node, 'id', '?')}: {e}")

        # Process relationships with property validation
        print(f"DEBUG: Processing {len(graph.relationships)} relationships...")
        for rel in graph.relationships:
            try:
                rel_dict = dict(rel)
                # Convert properties to native types
                properties = {}
                for k, v in rel_dict.get('properties', {}).items():
                    try:
                        properties[k] = ensure_neo4j_compatible(v, f"rel.{rel_dict.get('start_node_id', '?')}-{rel_dict.get('type', '?')}->{rel_dict.get('end_node_id', '?')}.{k}")
                    except Exception as e:
                        print(f"Error processing relationship property '{k}': {e}")

                # Create a clean relationship dictionary
                clean_rel = {
                    'start_node_id': str(rel_dict.get('start_node_id', '')),
                    'end_node_id': str(rel_dict.get('end_node_id', '')),
                    'type': str(rel_dict.get('type', '')),
                    'properties': properties
                }
                relationships.append(clean_rel)
            except Exception as e:
                print(f"Error processing relationship: {e}")

        print(f"DEBUG: After processing - nodes: {len(nodes)}, relationships: {len(relationships)}")
        print(f"Processed {len(nodes)} nodes and {len(relationships)} relationships with Neo4j-compatible types")

        # Create a clean Neo4jGraph object with validated data
        from neo4j_graphrag.experimental.components.types import Neo4jGraph, Neo4jNode, Neo4jRelationship

        # Create Neo4jNode objects
        print("Creating Neo4j nodes and relationships...")
        neo4j_nodes = []
        for node in nodes:
            try:
                neo4j_node = Neo4jNode(
                    id=node['id'],
                    label=node['label'],
                    properties=node.get('properties', {})
                )
                neo4j_nodes.append(neo4j_node)
            except Exception as e:
                print(f"Error creating Neo4j node {node.get('id', '?')}: {e}")

        # Create Neo4jRelationship objects
        neo4j_relationships = []
        for rel in relationships:
            try:
                neo4j_rel = Neo4jRelationship(
                    start_node_id=rel['start_node_id'],
                    end_node_id=rel['end_node_id'],
                    type=rel['type'],
                    properties=rel.get('properties', {})
                )
                neo4j_relationships.append(neo4j_rel)
            except Exception as e:
                rel_id = f"{rel.get('start_node_id', '?')} -[{rel.get('type', '?')}]-> {rel.get('end_node_id', '?')}"
                print(f"Error creating relationship {rel_id}: {e}")

        # Create the final graph
        neo4j_graph = Neo4jGraph(nodes=neo4j_nodes, relationships=neo4j_relationships)

        # Write to Neo4j
        print(f"Writing {len(neo4j_nodes)} nodes and {len(neo4j_relationships)} relationships to Neo4j...")
        writer_result = await writer.run(neo4j_graph)
        print(f"Successfully wrote to Neo4j: {writer_result.status}")

        # Print summary of nodes and relationships by type
        print("\n=== Neo4j Write Summary ===")
        
        # Count nodes by label
        node_counts = {}
        for node in neo4j_nodes:
            label = node.label
            node_counts[label] = node_counts.get(label, 0) + 1
        
        # Print node counts
        print("\nNode Types Written:")
        for node_type in SCHEMA.node_types:
            count = node_counts.get(node_type.label, 0)
            print(f"- {node_type.label}: {count}")
        
        # Count relationships by type
        rel_counts = {}
        for rel in neo4j_relationships:
            rel_type = rel.type
            rel_counts[rel_type] = rel_counts.get(rel_type, 0) + 1
        
        # Print relationship counts
        print("\nRelationship Types Written:")
        for rel_type in SCHEMA.relationship_types:
            count = rel_counts.get(rel_type.label, 0)
            print(f"- {rel_type.label}: {count}")
        
        # Print total counts
        print(f"\nTotal Nodes Written: {len(neo4j_nodes)}")
        print(f"Total Relationships Written: {len(neo4j_relationships)}")
        print("================================\n")

    except Exception as e:
        print(f"An error occurred in main: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Close the driver when done
        if driver:
            driver.close()
            print("Neo4j driver closed.")

if __name__ == "__main__":
    asyncio.run(main())
