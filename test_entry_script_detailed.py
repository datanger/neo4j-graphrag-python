#!/usr/bin/env python3
"""
详细测试启动脚本的跨作用域变量识别功能
"""

import asyncio
import os
from pathlib import Path

# 添加项目根目录到Python路径
import sys
sys.path.append(str(Path(__file__).parent))

from neo4j_graphrag.experimental.components.code_extractor.matlab.matlab_extractor import (
    MatlabExtractor, _global_registry
)
from neo4j_graphrag.experimental.components.types import (
    TextChunk, TextChunks, DocumentInfo, LexicalGraphConfig
)

# 使用与主程序相同的schema和examples
from examples.customize.build_graph.pipeline.kg_builder_from_code import SCHEMA, EXAMPLES

class MockLLM:
    """Mock LLM for demonstration purposes."""
    async def generate(self, prompt: str) -> str:
        return "Mock description generated by LLM"

async def test_cross_scope_variable_detection():
    """测试跨作用域变量识别功能"""
    print("=== 测试跨作用域变量识别功能 ===")
    
    # 创建测试目录和文件
    test_dir = Path("test_cross_scope")
    test_dir.mkdir(exist_ok=True)
    
    # 创建启动脚本 - 定义变量并调用其他脚本
    entry_script_content = """
% 启动脚本 - main.m
% 定义全局变量
config_file = 'config.json';
data_path = '/data/input';
output_dir = '/data/output';

% 调用其他脚本（按执行顺序）
setup_config;
load_data;
process_data;
save_results;
"""
    
    entry_script_path = test_dir / "main.m"
    with open(entry_script_path, 'w') as f:
        f.write(entry_script_content)
    
    # 创建其他脚本 - 使用启动脚本中定义的变量
    scripts = {
        "setup_config.m": """
% 设置配置脚本
function setup_config()
    global config_file;
    disp('Setting up configuration...');
    config = loadjson(config_file);
    workspace_path = '/workspace';
end
""",
        "load_data.m": """
% 加载数据脚本
function load_data()
    global data_path;
    disp('Loading data...');
    input_file = data_path;
    raw_data = load(input_file);
    data_size = size(raw_data);
end
""",
        "process_data.m": """
% 数据处理脚本
function process_data()
    global output_dir;
    disp('Processing data...');
    processed_data = raw_data * 2;
    result_file = fullfile(output_dir, 'result.mat');
end
""",
        "save_results.m": """
% 保存结果脚本
function save_results()
    disp('Saving results...');
    save(result_file, 'processed_data');
    disp('Results saved successfully');
end
"""
    }
    
    for filename, content in scripts.items():
        with open(test_dir / filename, 'w') as f:
            f.write(content)
    
    print(f"创建测试文件在: {test_dir}")
    
    # 测试1: 不使用启动脚本
    print("\n--- 测试1: 不使用启动脚本 ---")
    MatlabExtractor.reset_global_registry()
    
    llm = MockLLM()
    extractor = MatlabExtractor(llm=llm)
    
    # 处理所有文件
    for file_path in test_dir.glob("*.m"):
        with open(file_path, 'r') as f:
            content = f.read()
        
        chunk = TextChunk(
            text=content,
            index=0,
            metadata={"file_path": str(file_path), "file_name": file_path.name, "code_type": "matlab"}
        )
        
        doc_info = DocumentInfo(
            path=str(file_path),
            metadata={"name": file_path.name}
        )
        
        result = await extractor.run(
            chunks=TextChunks(chunks=[chunk]),
            schema=SCHEMA,
            document_info=doc_info,
            lexical_graph_config=LexicalGraphConfig(),
            examples=EXAMPLES,
            enable_post_processing=True,
        )
    
    print(f"不使用启动脚本的结果: {len(result.graph.nodes)} 节点, {len(result.graph.relationships)} 关系")
    
    # 测试2: 使用启动脚本
    print("\n--- 测试2: 使用启动脚本 ---")
    MatlabExtractor.reset_global_registry()
    
    extractor_with_entry = MatlabExtractor(llm=llm, entry_script_path=str(entry_script_path))
    
    # 处理所有文件
    for file_path in test_dir.glob("*.m"):
        with open(file_path, 'r') as f:
            content = f.read()
        
        chunk = TextChunk(
            text=content,
            index=0,
            metadata={"file_path": str(file_path), "file_name": file_path.name, "code_type": "matlab"}
        )
        
        doc_info = DocumentInfo(
            path=str(file_path),
            metadata={"name": file_path.name}
        )
        
        result = await extractor_with_entry.run(
            chunks=TextChunks(chunks=[chunk]),
            schema=SCHEMA,
            document_info=doc_info,
            lexical_graph_config=LexicalGraphConfig(),
            examples=EXAMPLES,
            enable_post_processing=True,
        )
    
    print(f"使用启动脚本的结果: {len(result.graph.nodes)} 节点, {len(result.graph.relationships)} 关系")
    
    # 显示启动脚本分析的信息
    print(f"\n启动脚本执行流程: {_global_registry.entry_script_execution_flow}")
    print(f"启动脚本变量作用域: {_global_registry.entry_script_variable_scope}")
    print(f"执行顺序: {_global_registry.execution_order}")
    
    # 清理测试文件
    import shutil
    shutil.rmtree(test_dir)
    print(f"\n清理测试文件: {test_dir}")

if __name__ == "__main__":
    asyncio.run(test_cross_scope_variable_detection()) 